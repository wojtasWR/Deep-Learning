{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b0d03d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)\n",
    "\n",
    "trainset, validationset = random_split(dataset, [40000, 10000])\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, prefetch_factor=2, num_workers=2,pin_memory=True)\n",
    "validationloader = torch.utils.data.DataLoader(validationset, batch_size=batch_size, shuffle=True, prefetch_factor=2, num_workers=2,pin_memory=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, prefetch_factor=2, num_workers=2,pin_memory=True)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d14ce263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(net, dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    \n",
    "    for data in dataloader:\n",
    "        images, labels = data\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images.view(images.size(0), -1))\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return 100 * correct / total\n",
    "\n",
    "def numel(m: torch.nn.Module, only_trainable: bool = False):\n",
    "    \"\"\"\n",
    "    returns the total number of parameters used by `m` (only counting\n",
    "    shared parameters once); if `only_trainable` is True, then only\n",
    "    includes parameters with `requires_grad = True`\n",
    "    \"\"\"\n",
    "    parameters = m.parameters()\n",
    "    if only_trainable:\n",
    "        parameters = list(p for p in parameters if p.requires_grad)\n",
    "    unique = dict((p.data_ptr(), p) for p in parameters).values()\n",
    "    return sum(p.numel() for p in unique)\n",
    "\n",
    "class LinearBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearBlock, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "        self.bn = nn.BatchNorm1d(output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class ResLinearBlock(nn.Module):\n",
    "    def __init__(self, input_dim, dim):\n",
    "        super(ResLinearBlock, self).__init__()\n",
    "        self.fc1 = LinearBlock(input_dim, dim)\n",
    "        self.fc2 = LinearBlock(dim, input_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        out += x    \n",
    "        return out\n",
    "    \n",
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, input_dim ,output_dim, layers, block = LinearBlock, num_classes=10):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.layers = layers\n",
    "        self.block = block\n",
    "        self.feed = self.make_layers()\n",
    "        \n",
    "\n",
    "    def make_layers(self):\n",
    "        network_layers = []\n",
    "        network_layers.append(\n",
    "            LinearBlock(self.input_dim, self.layers[0])\n",
    "        )\n",
    "        \n",
    "        for i in range(len(self.layers) - 1):\n",
    "            network_layers.append(\n",
    "                self.block(self.layers[0], self.layers[i+1])\n",
    "            )\n",
    "            \n",
    "        network_layers.append(\n",
    "            nn.Linear(self.layers[0], self.output_dim)\n",
    "        )\n",
    "        \n",
    "\n",
    "        return nn.Sequential(*network_layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feed(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "720e02c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10171146\n"
     ]
    }
   ],
   "source": [
    "layers = [256 for i in range(8)] + [512 for i in range(8)] + [1024 for i in range(12)]\n",
    "net = LinearNet(32*32*3, 10, layers, block = ResLinearBlock)\n",
    "\n",
    "print(numel(net))\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if use_cuda else 'cpu')\n",
    "net = net.cuda(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters())#, #momentum=0.9)\n",
    "\n",
    "train_accuracy = []\n",
    "validation_accuracy = []\n",
    "\n",
    "validation_loss = []\n",
    "train_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dcd3b74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, training loss: 2.3392046888669333, validation loss: 1.988910008699466, validation accuracy: 34.99%\n",
      "Epoch: 1, training loss: 1.767229370581798, validation loss: 1.988910008699466, validation accuracy: 34.99%\n",
      "Epoch: 2, training loss: 1.5780096359741993, validation loss: 1.988910008699466, validation accuracy: 34.99%\n",
      "Epoch: 3, training loss: 1.4751014923438048, validation loss: 1.988910008699466, validation accuracy: 34.99%\n",
      "Epoch: 4, training loss: 1.4720748586532397, validation loss: 1.988910008699466, validation accuracy: 34.99%\n",
      "Epoch: 5, training loss: 1.4020152963124788, validation loss: 1.5180623286809676, validation accuracy: 48.18%\n",
      "Epoch: 6, training loss: 1.2851830140138283, validation loss: 1.5180623286809676, validation accuracy: 48.18%\n",
      "Epoch: 7, training loss: 1.194488477630493, validation loss: 1.5180623286809676, validation accuracy: 48.18%\n",
      "Epoch: 8, training loss: 1.1041421458507195, validation loss: 1.5180623286809676, validation accuracy: 48.18%\n",
      "Epoch: 9, training loss: 1.1201573270253646, validation loss: 1.5180623286809676, validation accuracy: 48.18%\n",
      "Epoch: 10, training loss: 1.0538009030696673, validation loss: 1.5443184222930517, validation accuracy: 51.84%\n",
      "Epoch: 11, training loss: 1.0006503138022544, validation loss: 1.5443184222930517, validation accuracy: 51.84%\n",
      "Epoch: 12, training loss: 0.9182362716931564, validation loss: 1.5443184222930517, validation accuracy: 51.84%\n",
      "Epoch: 13, training loss: 0.8505523613630197, validation loss: 1.5443184222930517, validation accuracy: 51.84%\n",
      "Epoch: 14, training loss: 0.8676543988478489, validation loss: 1.5443184222930517, validation accuracy: 51.84%\n",
      "Epoch: 15, training loss: 0.7486759733695251, validation loss: 1.68447867112282, validation accuracy: 50.73%\n",
      "Epoch: 16, training loss: 0.6753554225732119, validation loss: 1.68447867112282, validation accuracy: 50.73%\n",
      "Epoch: 17, training loss: 0.7612832498091918, validation loss: 1.68447867112282, validation accuracy: 50.73%\n",
      "Epoch: 18, training loss: 0.617036796724185, validation loss: 1.68447867112282, validation accuracy: 50.73%\n",
      "Epoch: 19, training loss: 0.5267725980434662, validation loss: 1.68447867112282, validation accuracy: 50.73%\n",
      "Epoch: 20, training loss: 0.45505532736961657, validation loss: 2.032181360782721, validation accuracy: 50.42%\n",
      "Epoch: 21, training loss: 0.4417456654019845, validation loss: 2.032181360782721, validation accuracy: 50.42%\n",
      "Epoch: 22, training loss: 0.41561602762876415, validation loss: 2.032181360782721, validation accuracy: 50.42%\n",
      "Epoch: 23, training loss: 0.37357945692462796, validation loss: 2.032181360782721, validation accuracy: 50.42%\n",
      "Epoch: 24, training loss: 0.34869644141350037, validation loss: 2.032181360782721, validation accuracy: 50.42%\n",
      "Epoch: 25, training loss: 0.3327044640214015, validation loss: 2.372735475882506, validation accuracy: 51.68%\n",
      "Epoch: 26, training loss: 0.2939091418416072, validation loss: 2.372735475882506, validation accuracy: 51.68%\n",
      "Epoch: 27, training loss: 0.24908800308520979, validation loss: 2.372735475882506, validation accuracy: 51.68%\n",
      "Epoch: 28, training loss: 0.2655782832358128, validation loss: 2.372735475882506, validation accuracy: 51.68%\n",
      "Epoch: 29, training loss: 0.24920689601164597, validation loss: 2.372735475882506, validation accuracy: 51.68%\n",
      "Epoch: 30, training loss: 0.22763078397092146, validation loss: 2.5842268405816493, validation accuracy: 51.62%\n",
      "Epoch: 31, training loss: 0.24057975659767786, validation loss: 2.5842268405816493, validation accuracy: 51.62%\n",
      "Epoch: 32, training loss: 0.22791639018135193, validation loss: 2.5842268405816493, validation accuracy: 51.62%\n",
      "Epoch: 33, training loss: 0.1811543700691217, validation loss: 2.5842268405816493, validation accuracy: 51.62%\n",
      "Epoch: 34, training loss: 0.19487558758984774, validation loss: 2.5842268405816493, validation accuracy: 51.62%\n",
      "Epoch: 35, training loss: 0.2638962237307659, validation loss: 2.799519447179941, validation accuracy: 50.83%\n",
      "Epoch: 36, training loss: 0.1603763739172465, validation loss: 2.799519447179941, validation accuracy: 50.83%\n",
      "Epoch: 37, training loss: 0.15906225622464448, validation loss: 2.799519447179941, validation accuracy: 50.83%\n",
      "Epoch: 38, training loss: 0.1603585988856279, validation loss: 2.799519447179941, validation accuracy: 50.83%\n",
      "Epoch: 39, training loss: 0.152580411436084, validation loss: 2.799519447179941, validation accuracy: 50.83%\n",
      "Epoch: 40, training loss: 0.14561395578755018, validation loss: 3.0403868601872373, validation accuracy: 50.72%\n",
      "Epoch: 41, training loss: 0.14487977373676422, validation loss: 3.0403868601872373, validation accuracy: 50.72%\n",
      "Epoch: 42, training loss: 0.13552827364168105, validation loss: 3.0403868601872373, validation accuracy: 50.72%\n",
      "Epoch: 43, training loss: 0.16656215073397526, validation loss: 3.0403868601872373, validation accuracy: 50.72%\n",
      "Epoch: 44, training loss: 0.12341805153454725, validation loss: 3.0403868601872373, validation accuracy: 50.72%\n",
      "Epoch: 45, training loss: 0.11868398101666035, validation loss: 3.265731719823984, validation accuracy: 52.01%\n",
      "Epoch: 46, training loss: 0.1339290006659352, validation loss: 3.265731719823984, validation accuracy: 52.01%\n",
      "Epoch: 47, training loss: 0.14198891080629367, validation loss: 3.265731719823984, validation accuracy: 52.01%\n",
      "Epoch: 48, training loss: 0.1516040673909279, validation loss: 3.265731719823984, validation accuracy: 52.01%\n",
      "Epoch: 49, training loss: 0.1094882932658761, validation loss: 3.265731719823984, validation accuracy: 52.01%\n",
      "Epoch: 50, training loss: 0.12137890043549049, validation loss: 3.2570488972541614, validation accuracy: 51.45%\n",
      "Epoch: 51, training loss: 0.12392588093494758, validation loss: 3.2570488972541614, validation accuracy: 51.45%\n",
      "Epoch: 52, training loss: 0.12731370993722707, validation loss: 3.2570488972541614, validation accuracy: 51.45%\n",
      "Epoch: 53, training loss: 0.11185023030982567, validation loss: 3.2570488972541614, validation accuracy: 51.45%\n",
      "Epoch: 54, training loss: 0.087099577467411, validation loss: 3.2570488972541614, validation accuracy: 51.45%\n",
      "Epoch: 55, training loss: 0.08789582404857263, validation loss: 3.499000323124421, validation accuracy: 50.8%\n",
      "Epoch: 56, training loss: 0.10459828795865178, validation loss: 3.499000323124421, validation accuracy: 50.8%\n",
      "Epoch: 57, training loss: 0.09675699858090435, validation loss: 3.499000323124421, validation accuracy: 50.8%\n",
      "Epoch: 58, training loss: 0.08865363722762619, validation loss: 3.499000323124421, validation accuracy: 50.8%\n",
      "Epoch: 59, training loss: 0.08796019747089116, validation loss: 3.499000323124421, validation accuracy: 50.8%\n",
      "Epoch: 60, training loss: 0.10322947742847297, validation loss: 3.464771111806234, validation accuracy: 51.07%\n",
      "Epoch: 61, training loss: 0.09829826994488637, validation loss: 3.464771111806234, validation accuracy: 51.07%\n",
      "Epoch: 62, training loss: 0.0961894370161761, validation loss: 3.464771111806234, validation accuracy: 51.07%\n",
      "Epoch: 63, training loss: 0.09064191250273815, validation loss: 3.464771111806234, validation accuracy: 51.07%\n",
      "Epoch: 64, training loss: 0.09060945663935481, validation loss: 3.464771111806234, validation accuracy: 51.07%\n",
      "Epoch: 65, training loss: 0.09892000260356909, validation loss: 3.393543695792174, validation accuracy: 51.86%\n",
      "Epoch: 66, training loss: 0.08794926640649255, validation loss: 3.393543695792174, validation accuracy: 51.86%\n",
      "Epoch: 67, training loss: 0.05840396789762263, validation loss: 3.393543695792174, validation accuracy: 51.86%\n",
      "Epoch: 68, training loss: 0.08130107927494325, validation loss: 3.393543695792174, validation accuracy: 51.86%\n",
      "Epoch: 69, training loss: 0.08646756872678033, validation loss: 3.393543695792174, validation accuracy: 51.86%\n",
      "Epoch: 70, training loss: 0.08614008061778851, validation loss: 3.6183640590080848, validation accuracy: 51.91%\n",
      "Epoch: 71, training loss: 0.07833598670549691, validation loss: 3.6183640590080848, validation accuracy: 51.91%\n",
      "Epoch: 72, training loss: 0.2817376623742091, validation loss: 3.6183640590080848, validation accuracy: 51.91%\n",
      "Epoch: 73, training loss: 0.05347486869551432, validation loss: 3.6183640590080848, validation accuracy: 51.91%\n",
      "Epoch: 74, training loss: 0.2546373635578232, validation loss: 3.6183640590080848, validation accuracy: 51.91%\n",
      "Epoch: 75, training loss: 0.2000947583657809, validation loss: 2.9485337917621317, validation accuracy: 52.07%\n",
      "Epoch: 76, training loss: 0.09188820985265267, validation loss: 2.9485337917621317, validation accuracy: 52.07%\n",
      "Epoch: 77, training loss: 0.2129850949232395, validation loss: 2.9485337917621317, validation accuracy: 52.07%\n",
      "Epoch: 78, training loss: 0.05702104461856951, validation loss: 2.9485337917621317, validation accuracy: 52.07%\n",
      "Epoch: 79, training loss: 0.02238884874028512, validation loss: 2.9485337917621317, validation accuracy: 52.07%\n",
      "Epoch: 80, training loss: 0.01794742698220011, validation loss: 3.7939676076937943, validation accuracy: 51.73%\n",
      "Epoch: 81, training loss: 0.11119336878451017, validation loss: 3.7939676076937943, validation accuracy: 51.73%\n",
      "Epoch: 82, training loss: 0.04919040675322788, validation loss: 3.7939676076937943, validation accuracy: 51.73%\n",
      "Epoch: 83, training loss: 0.03432967846031086, validation loss: 3.7939676076937943, validation accuracy: 51.73%\n",
      "Epoch: 84, training loss: 0.04196094076495427, validation loss: 3.7939676076937943, validation accuracy: 51.73%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-574582d6477c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mt_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-a9c8cc270b12>\u001b[0m in \u001b[0;36mcompute_accuracy\u001b[0;34m(net, dataloader)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# since we're not training, we don't need to calculate the gradients for our outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1139\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training Loop\n",
    "for epoch in range(150):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # wrap them in Variable\n",
    "        #inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs.view(inputs.size(0), -1))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    #if epoch % 10== 0 and epoch!=0 :\n",
    "        #torch.save(net.state_dict(), f\"./shallow_linear_3_regular_{epoch}\")\n",
    "        \n",
    "        \n",
    "    if epoch % 5 == 0:\n",
    "        with torch.no_grad(): \n",
    "            v_loss = 0.0\n",
    "            for j, data in enumerate(validationloader, 0):\n",
    "                inputs, labels = data\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = net(inputs.view(inputs.size(0), -1))\n",
    "                v_loss += criterion(outputs, labels).item()\n",
    "                \n",
    "            validation_loss.append(v_loss/j)\n",
    "            \n",
    "            v_accuracy = compute_accuracy(net, validationloader)\n",
    "            validation_accuracy.append(v_accuracy)\n",
    "            \n",
    "            train_loss.append(running_loss/i)\n",
    "            t_accuracy = compute_accuracy(net, trainloader)\n",
    "            train_accuracy.append(t_accuracy)\n",
    "    \n",
    "    print(f\"Epoch: {epoch}, training loss: {running_loss/i}, validation loss: {v_loss/j}, validation accuracy: {v_accuracy}%\")\n",
    "                \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1957f7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:15: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"papertype\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  from ipykernel import kernelapp as app\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:15: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"frameon\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  from ipykernel import kernelapp as app\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:29: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"papertype\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:29: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"frameon\" which is no longer supported as of 3.3 and will become an error two minor releases later\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs_plot = [5*(i + 1) for i in range(epoch//5 + 1)]\n",
    "\n",
    "plt.plot(epochs_plot[:-3], validation_loss[:-3])\n",
    "plt.plot(epochs_plot[:-3], train_loss[:-3])\n",
    "plt.title(\"Loss Plot\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Validation Loss\", \"Training Loss\"])\n",
    "#plt.show()\n",
    "plt.savefig(\"linear_deep_resnet_75_loss.png\", dpi=None, facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "        frameon=None, metadata=None)\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(epochs_plot[:-3], validation_accuracy[:-3])\n",
    "plt.plot(epochs_plot[:-3], train_accuracy[:-2])\n",
    "plt.title(\"Accuracy Plot\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Validation Accuracy\", \"Training Accuracy\"])\n",
    "#plt.show()\n",
    "plt.savefig(\"linear_deep_resnet_75_acc.png\", dpi=None, facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "        frameon=None, metadata=None)\n",
    "\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70556e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 46 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images.view(images.size(0), -1))\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c84205a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2%1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "538987bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 3072])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.view(inputs.size(0), -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dbed1494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_plot[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd1734a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-8.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m69"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
